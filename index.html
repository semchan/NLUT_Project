<html>

<html>
<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <meta name="description" content="DESCRIPTION META TAG">
  <meta property="og:title" content="SOCIAL MEDIA TITLE TAG"/>
  <meta property="og:description" content="SOCIAL MEDIA DESCRIPTION TAG TAG"/>
  <meta property="og:url" content="URL OF THE WEBSITE"/>
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
  <meta property="og:image" content="static/image/your_banner_image.png" />
  <meta property="og:image:width" content="1200"/>
  <meta property="og:image:height" content="630"/>


  <meta name="twitter:title" content="TWITTER BANNER TITLE META TAG">
  <meta name="twitter:description" content="TWITTER BANNER DESCRIPTION META TAG">
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
  <meta name="twitter:image" content="static/images/your_twitter_banner_image.png">
  <meta name="twitter:card" content="summary_large_image">
  <!-- Keywords for your paper to be indexed by-->
  <meta name="keywords" content="KEYWORDS SHOULD BE PLACED HERE">
  <meta name="viewport" content="width=device-width, initial-scale=1">


  <title>NLUT</title>
  <link rel="icon" type="image/x-icon" href="static/images/favicon.ico">
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
  rel="stylesheet">


  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
</head>
<body>


  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h3 class="xtitle is-1 publication-title">NLUT:
            Neural-based 3D Lookup Tables for Video Photorealistic Style Transfer</h3>
            <div class="is-size-5 publication-authors">
              <!-- Paper authors -->

                <span class="author-block">
                  <a href="https://scholar.google.com.hk/citations?user=HvWZhM4AAAAJ&hl=zh-CN" target="_blank">Yaosen Chen</a><sup>1</sup>
                </span>
                  <span class="author-block">
                    Han Yang<sup>1</sup>
                  </span>
                  <span class="author-block">
                    Yuexin Yang<sup>1</sup>
                  </span>
                  <span class="author-block">
                    Yuegen Liu<sup>1</sup>
                  </span>
                  <br>
                  <span class="author-block">
                    <a href="https://scholar.google.com.hk/citations?user=tfJVFEcAAAAJ&hl=zh-CN" target="_blank">Wei Wang</a><sup>*,1,2</sup>
                  </span>
                  <span class="author-block">
                    Xuming Wen<sup>1,2</sup>
                  </span>
                  <span class="author-block">
                    Chaoping Xie<sup>1,2</sup>
                  </span>



                  </div>
                  <br>
                  <div class="is-size-5 publication-authors">
                    <span class="author-block">
                      <sup>1</sup> Media Intelligence Laboratory, ChengDu Sobey Digital Technology Co., Ltd &nbsp;&nbsp;&nbsp;
                      <sup>2</sup> Peng Cheng Laboratory &nbsp;&nbsp;&nbsp;
                      </span>
                    <span class="eql-cntrb"><small><br><sup>*</sup>Indicates The Corresponding Author</small></span>
                  </div>
                  <div class="column has-text-centered">
                    <div class="publication-links">
                         <!-- Arxiv PDF link -->
                      <span class="link-block">
                        <a href="https://arxiv.org/pdf/2303.09170.pdf" target="_blank"
                        class="external-link ">
                        <span class="icon">
                          <i class="fas fa-file-pdf"></i>
                        </span>
                        <span>Paper</span>
                      </a>
                    </span>

                  <!-- Github link -->
                  <span class="link-block">
                    <a href="https://github.com/semchan/NLUT" target="_blank"
                    class="external-link ">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span>


                </a>
              </span>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>















<head>
  <title>NLUT</title>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, user-scalable=no, minimum-scale=1.0, maximum-scale=1.0">
  <link type="text/css" rel="stylesheet" href="main.css">
</head>












  <p class="section"> </p>
    <section id="teaser" class="flex-row">
            
                <img width="90%" src="assets/teaser.png" >
            </a>
        <p class="caption">
            <strong>Transferring photorealistic style with a style image for the video.</strong>Given a content video and a style image, our method is able to efficiently generate photorealistic stylized video.
        </p>
    </section>

  <p class="section">Abstract</p>
  <p>
    Video photorealistic style transfer is desired to generate videos with a similar photorealistic style to the style image while maintaining temporal consistency. However, existing methods obtain stylized video sequences by performing frame-by-frame photorealistic style transfer, which is inefficient and does not ensure the temporal consistency of the stylized video. To address this issue, we use neural network-based 3D Lookup Tables (LUTs) for the photorealistic transfer of videos, achieving a balance between efficiency and effectiveness. We first train a neural network for generating photorealistic stylized 3D LUTs on a large-scale dataset; then, when performing photorealistic style transfer for a specific video, we select a keyframe and style image in the video as the data source and fine-turn the neural network; finally, we query the 3D LUTs generated by the fine-tuned neural network for the colors in the video, resulting in a super-fast photorealistic style transfer, even processing 8K video takes less than 2 millisecond per frame. The experimental results show that our method not only realizes the photorealistic style transfer of arbitrary style images but also outperforms the existing methods in terms of visual quality and consistency. Project page:https://semchan.github.io/NLUT_Project.<br>
  </p>
  <p class="section" id="results">Approach</p>
  <img src="s1.png" class="architecture">
  <p>
 In our network structure, we first extract the features of a pair of down-sampled style image and content image by the pre-trained VGG model. Then, further feature extraction and fusion of content features and style features of different scales are performed respectively. Finally, a classifier is used to predict the weight of the linear combination of basic LUTs. The parameters of the basic LUTs are learned simultaneously with the network. During the stylization process, only the content image is needed as input, and the reconstructed 3D LUT is used for colour query and interpolation to output the stylized image. 
  </p>
  
  <img src="assets/metd.png" class="architecture">
  <p>
<strong>Overview of neuarl-based 3D lookup tables for video photorealistic style transfer.</strong>
(a). First, we randomly sample the style image and content image on a large-scale image dataset to train a neural LUT Network and the initial 3D LUT; (b). Then we use the trained Neural LUT Network and 3D LUT to conduct tuning training on the content image from the specified video and the specified style image to generate an optimal style 3D LUT; (c). Finally, we use the generated style 3D LUT to interpolate and look up the colors in the content video to get the stylized video.


  </p>

  <p class="section" id="results">Results</p>
  <div class="text-to-reuslts">
    <div class="mono-depth-results-container">
      <div class="nyu-img-comp-container">
        <div class="img-comp-img img-comp-base">
          <video id="vid4" autoplay muted loop class="kitti-image">
            <source src="assets/src/city.mp4" type="video/mp4" />
          </video>
        </div>
        <div class="img-comp-img img-comp-overlay">
          <video id="vid5" autoplay muted loop class="kitti-image">
            <source src="assets/nlut/city.mp4" type="video/mp4" />
          </video>
        </div>
      </div>
    </div>

    <div class="mono-depth-results-container">
      <div class="nyu-img-comp-container">
        <div class="img-comp-img img-comp-base">
          <video id="vid6" autoplay muted loop class="kitti-image">
            <source src="assets/src/stream2.mp4" type="video/mp4" />
          </video>
        </div>
        <div class="img-comp-img img-comp-overlay">
          <video id="vid7" autoplay muted loop class="kitti-image">
            <source src="assets/nlut/stream2.mp4" type="video/mp4" />
          </video>
        </div>
      </div>
    </div>
    <div class="mono-depth-results-container">
      <div class="nyu-img-comp-container">
        <div class="img-comp-img img-comp-base">
          <video id="vid6" autoplay muted loop class="kitti-image">
            <source src="assets/src/kelly.mp4" type="video/mp4" />
          </video>
        </div>
        <div class="img-comp-img img-comp-overlay">
          <video id="vid7" autoplay muted loop class="kitti-image">
            <source src="assets/nlut/kelly.mp4" type="video/mp4" />
          </video>
        </div>
      </div>
    </div>
    <div class="mono-depth-results-container">
      <div class="nyu-img-comp-container">
        <div class="img-comp-img img-comp-base">
          <video id="vid6" autoplay muted loop class="kitti-image">
            <source src="assets/src/night.mp4" type="video/mp4" />
          </video>
        </div>
        <div class="img-comp-img img-comp-overlay">
          <video id="vid7" autoplay muted loop class="kitti-image">
            <source src="assets/nlut/night.mp4" type="video/mp4" />
          </video>
        </div>
      </div>
    </div>
    <div class="mono-depth-results-container">
      <div class="nyu-img-comp-container">
        <div class="img-comp-img img-comp-base">
          <video id="vid6" autoplay muted loop class="kitti-image">
            <source src="assets/src/pedestrian.mp4" type="video/mp4" />
          </video>
        </div>
        <div class="img-comp-img img-comp-overlay">
          <video id="vid7" autoplay muted loop class="kitti-image">
            <source src="assets/nlut/pedestrian.mp4" type="video/mp4" />
          </video>
        </div>
      </div>
    </div>
    <div class="mono-depth-results-container">
      <div class="nyu-img-comp-container">
        <div class="img-comp-img img-comp-base">
          <video id="vid6" autoplay muted loop class="kitti-image">
            <source src="assets/src/sunset.mp4" type="video/mp4" />
          </video>
        </div>
        <div class="img-comp-img img-comp-overlay">
          <video id="vid7" autoplay muted loop class="kitti-image">
            <source src="assets/nlut/sunset.mp4" type="video/mp4" />
          </video>
        </div>
      </div>
    </div>
    <div class="mono-depth-results-container">
      <div class="nyu-img-comp-container">
        <div class="img-comp-img img-comp-base">
          <video id="vid6" autoplay muted loop class="kitti-image">
            <source src="assets/src/monkey.mp4" type="video/mp4" />
          </video>
        </div>
        <div class="img-comp-img img-comp-overlay">
          <video id="vid7" autoplay muted loop class="kitti-image">
            <source src="assets/nlut/monkey.mp4" type="video/mp4" />
          </video>
        </div>
      </div>
    </div>
    <div class="mono-depth-results-container">
      <div class="nyu-img-comp-container">
        <div class="img-comp-img img-comp-base">
          <video id="vid6" autoplay muted loop class="kitti-image">
            <source src="assets/src/girl.mp4" type="video/mp4" />
          </video>
        </div>
        <div class="img-comp-img img-comp-overlay">
          <video id="vid7" autoplay muted loop class="kitti-image">
            <source src="assets/nlut/girl.mp4" type="video/mp4" />
          </video>
        </div>
      </div>
    </div>
  </div>
  <div class="teaser-expand">
    <span class="material-symbols-outlined" onclick="teaser_expand_contract2(this)">expand_more</span>
  </div>
  <script>
    var vid1 = document.getElementById("vid1");
    var vid2 = document.getElementById("vid2");
    // var vid3 = document.getElementById("vid3");
    // var vid4 = document.getElementById("vid4");
    var count = 0;
    vid1.paly()
    var x = document.getElementById("vid1");
    if (vid1.played) {
      vid2.paly()
    }
    // if (x.played.start(0) == 0){
    //   vid2.paused()
    // }
    document.getElementById("demo").innerHTML = "Start: " + x.played.start(0)
    var playthem = function (e) {
      // count++;
      // if(count > 1) {
      if (vid1.start()) {
        vid2.start();
      }

      // vid3.play();
      // vid4.play();
    }
    vid1.addEventListener('canplay', playthem, false);
    vid2.addEventListener('canplay', playthem, false);
  </script>
  

  <p>
  </p>
  <p class="section" id="results">Comparison</p>
  <div class="text-to-3d-examplesss">
    <video width="100%" controls muted loop>
      <source src="assets/comparison/city.mp4" type="video/mp4">
      Your browser does not support the video tag.
    </video>
    <video width="100%" controls muted loop>
      <source src="assets/comparison/girl.mp4" type="video/mp4">
      Your browser does not support the video tag.
    </video>
    <video width="100%" controls muted loop>
      <source src="assets/comparison/kelly.mp4" type="video/mp4">
      Your browser does not support the video tag.
    </video>
    <video width="100%" controls muted loop>
      <source src="assets/comparison/monkey.mp4" type="video/mp4">
      Your browser does not support the video tag.
    </video>
    <video width="100%" controls muted loop>
      <source src="assets/comparison/night.mp4" type="video/mp4">
      Your browser does not support the video tag.
    </video>
    <video width="100%" controls muted loop>
      <source src="assets/comparison/passager.mp4" type="video/mp4">
      Your browser does not support the video tag.
    </video>
    <video width="100%" controls muted loop>
      <source src="assets/comparison/stream2.mp4" type="video/mp4">
      Your browser does not support the video tag.
    </video>
    <video width="100%" controls muted loop>
      <source src="assets/comparison/sunset.mp4" type="video/mp4">
      Your browser does not support the video tag.
    </video>
  </div>
  <div class="teaser-expand">
    <span class="material-symbols-outlined" onclick="teaser_expand_contract1(this)">expand_more</span>
  </div>



        <p class="caption">
            <strong>Consistency amd Efficiency Comparison:</strong>
        </p>
   <section id="Consistency">
    <section id="teaser" class="flex-row">
            <a href="assets/test_result.png" style="text-align: center;">
                <img width="50%" src="assets/test_result.png" >
            </a>

    </section>
        <p class="GPU Usage">
            <strong>GPU Usage:</strong>
        </p>
   <section id="Consistency">
    <section id="teaser" class="flex-row">
            <a href="assets/GPU Usage.png" style="text-align: center;">
                <img width="50%" src="assets/GPU Usage.png" >
            </a>

    </section>
    </section>
    </section>
        <p class="userstudy">
            <strong>userstudy:</strong>
        </p>
   <section id="Consistency">
    <section id="teaser" class="flex-row">
            <a href="assets/userstudy.png" style="text-align: center;">
                <img width="50%" src="assets/userstudy.png" >
            </a>

    </section>
    </section>

  <p class="section" id="BibTeX">BibTeX</p>

  <blockquote>
    <pre>
@misc{chen2023nlut,
      title={NLUT: Neural-based 3D Lookup Tables for Video Photorealistic Style Transfer},
      author={Yaosen Chen; Han Yang;Yuexin Yang;Yuegen Liu;Wei Wang; Xuming Wen; Chaoping Xie},
      year={2023},
      eprint={2302.xxx},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}
      </pre>
  </blockquote>


</div>

<script>

  const teaserContainer = document.getElementsByClassName("text-to-3d-examples")[0];
  function teaser_expand_contract(element) {
    if (element.textContent == "expand_more") {
      teaserContainer.style.setProperty("white-space", "unset");
      element.textContent = "expand_less";
    } else {
      teaserContainer.style.setProperty("white-space", "nowrap");
      element.textContent = "expand_more";
    }
  }

  const teaserContainer2 = document.getElementsByClassName("text-to-3d-examplesss")[0];
  function teaser_expand_contract1(e) {
    if (e.textContent == "expand_more") {
      teaserContainer2.style.setProperty("white-space", "unset");
      e.textContent = "expand_less";
    } else {
      teaserContainer2.style.setProperty("white-space", "nowrap");
      e.textContent = "expand_more";
    }
  }

  const teaserContainer3 = document.getElementsByClassName("text-to-reuslts")[0];
  function teaser_expand_contract2(e1) {
    if (e1.textContent == "expand_more") {
      teaserContainer3.style.setProperty("white-space", "unset");
      teaserContainer3.style.setProperty("display", "block");
      e1.textContent = "expand_less";
    } else {
      teaserContainer3.style.setProperty("display", "flex");
      e1.textContent = "expand_more";
    }
  }
</script>



<script async src="https://unpkg.com/es-module-shims@1.3.6/dist/es-module-shims.js"></script>

<script type="module">

  import * as THREE from "https://unpkg.com/three?module";

  import { OrbitControls } from "https://unpkg.com/three/examples/jsm/controls/OrbitControls.js?module";
  import { PCDLoader } from 'https://unpkg.com/three/examples/jsm/loaders/PCDLoader.js?module';

  let cameras = [], scenes = [], renderers = [];
  // let path = "assets/kitchen_every_10.pcd";
  // let path = "assets/bedroom_every_10.pcd";
  let renderer_elements = document.getElementsByClassName("viewer-3d");
  let metadata = {
    "kitchen": {
      "path": "assets/kitchen_every_10.pcd",
      "posx": 3,
      "posy": 3,
      "posz": 9,
      "rotx": -0.25,
      "roty": 0.5,
      "rotz": 0.1,
    },
    "bedroom": {
      "path": "assets/bedroom_every_10.pcd",
      "posx": -0.07,
      "posy": 0.41,
      "posz": 10,
      "rotx": -0.04,
      "roty": 0.0,
      "rotz": 0.0,
    },
  };

  init();
  render();

  function init() {
    for (let i = 0; i < renderer_elements.length; i++) {
      let renderer_element = renderer_elements[i];
      if (renderer_element.getElementsByTagName("canvas").length != 0) {
        // Already initialized.
        continue;
      }
      let data = metadata[renderer_element.id];
      let path = data["path"];
      let renderer = new THREE.WebGLRenderer({ antialias: true });
      renderers.push(renderer);
      renderer.setPixelRatio(window.devicePixelRatio);
      renderer.setSize(renderer_element.clientWidth, renderer_element.clientWidth);
      renderer_element.appendChild(renderer.domElement);

      let scene = new THREE.Scene();
      scenes.push(scene);
      scene.background = new THREE.Color(0xeeeeee);

      let camera = new THREE.PerspectiveCamera(30, 1, 0.01, 40);
      cameras.push(camera);
      // camera.position.set( 0, 0, 10 );
      camera.position.set(data["posx"], data["posy"], data["posz"]);
      camera.rotation.x = data["rotx"];
      camera.rotation.y = data["roty"];
      camera.rotation.z = data["rotz"];

      scene.add(camera);

      const controls = new OrbitControls(camera, renderer.domElement);
      controls.addEventListener('change', render); // use if there is no animation loop
      controls.minDistance = 0.5;
      controls.maxDistance = 10;

      const loader = new PCDLoader();
      loader.load(path, function (points) {

        points.geometry.center();
        points.geometry.rotateX(Math.PI);
        points.name = path;
        points.material.size *= 8;
        scene.add(points);
        render();
      });
    }
  }

  const resizeObserver = new ResizeObserver((entries) => {
    for (const entry of entries) {
      for (const renderer of renderers) {
        renderer.setSize(entry.contentRect.width, entry.contentRect.width);
      }
    }
  });

  for (const renderer_element of renderer_elements) {
    resizeObserver.observe(renderer_element);
  }

  function render() {
    for (let i = 0; i < scenes.length; i++) {
      renderers[i].render(scenes[i], cameras[i]);
    }
  }

  const imageDepthResizeObserver = new ResizeObserver((entries) => {
    initComparisons();
  });

  imageDepthResizeObserver.observe(document.getElementsByClassName('mono-depth-results-container')[0]);

  var baseImages = document.getElementsByClassName("img-comp-base");
  var overlayImages = document.getElementsByClassName("img-comp-overlay");
  // Sliders for image / depth comparison.
  function initComparisons() {
    var i;
    for (i = 0; i < overlayImages.length; i++) {
      /* Once for each "overlay" element:
      pass the "overlay" element as a parameter when executing the compareImages function: */
      compareImages(overlayImages[i], baseImages[i]);
    }
    function compareImages(img, base_img) {
      var slider, img, clicked = 0, w, h;
      /* Get the width and height of the img element */
      w = base_img.offsetWidth;
      h = base_img.offsetHeight;
      /* Set the width of the img element to 50%: */
      img.style.width = (w / 2) + "px";
      /* Create slider: */
      let createSlider = (img.parentElement.getElementsByClassName('img-comp-slider').length == 0);
      if (createSlider) {
        slider = document.createElement("DIV");
        slider.setAttribute("class", "img-comp-slider");
        /* Insert slider */
        img.parentElement.insertBefore(slider, img);
      } else {
        slider = img.parentElement.getElementsByClassName("img-comp-slider")[0];
      }
      /* Position the slider in the middle: */
      slider.style.top = (h / 2) - (slider.offsetHeight / 2) + "px";
      slider.style.left = (w / 2) - (slider.offsetWidth / 2) + "px";
      /* Execute a function when the mouse button is pressed: */
      slider.addEventListener("mousedown", slideReady);
      /* And another function when the mouse button is released: */
      window.addEventListener("mouseup", slideFinish);
      /* Or touched (for touch screens: */
      slider.addEventListener("touchstart", slideReady);
      /* And released (for touch screens: */
      window.addEventListener("touchend", slideFinish);
      function slideReady(e) {
        /* Prevent any other actions that may occur when moving over the image: */
        e.preventDefault();
        /* The slider is now clicked and ready to move: */
        clicked = 1;
        /* Execute a function when the slider is moved: */
        window.addEventListener("mousemove", slideMove);
        window.addEventListener("touchmove", slideMove);
      }
      function slideFinish() {
        /* The slider is no longer clicked: */
        clicked = 0;
      }
      function slideMove(e) {
        var pos;
        /* If the slider is no longer clicked, exit this function: */
        if (clicked == 0) return false;
        /* Get the cursor's x position: */
        pos = getCursorPos(e)
        /* Prevent the slider from being positioned outside the image: */
        if (pos < 0) pos = 0;
        if (pos > w) pos = w;
        /* Execute a function that will resize the overlay image according to the cursor: */
        slide(pos);
      }
      function getCursorPos(e) {
        var a, x = 0;
        e = (e.changedTouches) ? e.changedTouches[0] : e;
        /* Get the x positions of the image: */
        a = img.getBoundingClientRect();
        /* Calculate the cursor's x coordinate, relative to the image: */
        x = e.pageX - a.left;
        /* Consider any page scrolling: */
        x = x - window.pageXOffset;
        return x;
      }
      function slide(x) {
        /* Resize the image: */
        img.style.width = x - 0.05 + "px";
        /* Position the slider: */
        slider.style.left = img.offsetWidth - (slider.offsetWidth / 2) + "px";
      }
    }
  }

  initComparisons();

</script>

</body>

</html>
